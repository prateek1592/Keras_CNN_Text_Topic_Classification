{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Tutorial on usage of pre-trained embeddings in topic classification\n",
    "\n",
    "Most code in this notebook is taken from the [excellent tutorial page](https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html). The goal of this notebook was to understand, in depth, the usage of CNNs in text classification - have never used these before in combination. The notebook has some notes, pointers, learnings, and is largely for a self-learning purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19997 texts.\n"
     ]
    }
   ],
   "source": [
    "# Extracting files - One off\n",
    "\"\"\"\n",
    "import tarfile\n",
    "import zipfile\n",
    "\n",
    "tf = tarfile.open(\"news20.tar.gz\")\n",
    "tf.extractall()\n",
    "tf.close()\n",
    "\n",
    "with zipfile.ZipFile(\"glove.6B.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall()\n",
    "\"\"\"\n",
    "    \n",
    "\"\"\"Basic Pre-processing\"\"\"\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "# Look Ma, no pandas!\n",
    "\n",
    "TEXT_DATA_DIR = 'data'\n",
    "\n",
    "texts = []  # list of text samples\n",
    "labels_index = {}  # dictionary mapping label name to numeric id\n",
    "labels = []  # list of label ids\n",
    "for name in sorted(os.listdir(TEXT_DATA_DIR)):\n",
    "    path = os.path.join(TEXT_DATA_DIR, name)\n",
    "    if os.path.isdir(path):\n",
    "        label_id = len(labels_index)\n",
    "        labels_index[name] = label_id\n",
    "        for fname in sorted(os.listdir(path)):\n",
    "            if fname.isdigit():\n",
    "                fpath = os.path.join(path, fname)\n",
    "                f = open(fpath, encoding='latin-1')\n",
    "                t = f.read()\n",
    "                i = t.find('\\n\\n')  # skip header\n",
    "                if i > 0:\n",
    "                    t = t[i:]\n",
    "                texts.append(t)\n",
    "                f.close()\n",
    "                labels.append(label_id)\n",
    "\n",
    "print('Found %s texts.' % len(texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formatting the problem to suit Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Anaconda3-5.2.0-Linux-x86_64/envs/jupyter-apf/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 174074 unique tokens.\n",
      "Shape of data tensor: (19997, 1000)\n",
      "Shape of label tensor: (19997, 20)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding, Input, Conv1D, MaxPooling1D, Flatten, Dense, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.utils import plot_model\n",
    "\n",
    "MAX_NB_WORDS = 20000\n",
    "MAX_SEQUENCE_LENGTH = 1000\n",
    "VALIDATION_SPLIT = 0.2\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "labels = to_categorical(np.asarray(labels))\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)\n",
    "\n",
    "# split the data into a training set and a validation set\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "nb_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n",
    "\n",
    "x_train = data[:-nb_validation_samples]\n",
    "y_train = labels[:-nb_validation_samples]\n",
    "x_val = data[-nb_validation_samples:]\n",
    "y_val = labels[-nb_validation_samples:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the embeddings matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "GLOVE_DIR = 'vectors'\n",
    "EMBEDDING_DIM = 100\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join(GLOVE_DIR, 'glove.6B.' + str(EMBEDDING_DIM) + 'd.txt'), encoding = 'utf-8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding matrix, with one row for each word in *word_index*, denoting its embedding vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(word_index)+1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Going through the model, layer-by-layer\n",
    "\n",
    "### We start with Input layer...\n",
    "\n",
    "From the [docs](https://keras.io/layers/core/)\n",
    "\n",
    "1st argument is **shape** - A shape tuple, *not including the batch size*. For instance, shape=(32,) indicates that the expected input will be batches of 32-dimensional vectors.\n",
    "\n",
    "A less-used alternative is **batch_shape**: A shape tuple, *including the batch size*. For instance, batch_shape=(10, 32) indicates that the expected input will be batches of 10 32-dimensional vectors.  batch_shape=(None, 32) indicates batches of an arbitrary number of 32-dimensional vectors.\n",
    "\n",
    "This is so weird. So basically, logically speaking shape=(,32) might be more sensible, but that's not really the case!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Input Layer\"\"\"\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding layer...\n",
    "\n",
    "Creating a non-trainable word-embedding layer. From the [reference](https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html):\n",
    "\n",
    "$$\\text{All that the Embedding layer does is to map the integer inputs to the vectors found at the corresponding index in the embedding}$$ $$\\text{matrix, i.e. the sequence [1, 2] would be converted to [embeddings[1], embeddings[2]]. This means that the output}$$\n",
    "$$\\text{of the Embedding layer will be a 3D tensor of shape (samples, sequence_length, embedding_dim)}$$\n",
    "\n",
    "It becomes clearer by the trial shown in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 1000) (20, 1000, 100)\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = Embedding(len(word_index)+1, EMBEDDING_DIM, weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH, trainable=False)\n",
    "\n",
    "\"\"\"Trying out the embedding layer to understand input / output\"\"\"\n",
    "trial_samples = 20\n",
    "trial_model = Sequential()\n",
    "trial_model.add(embedding_layer)\n",
    "\n",
    "trial_model.compile('adam', 'mse')\n",
    "output_array = trial_model.predict(x_train[:trial_samples])\n",
    "# assert output_array.shape == (trial_samples, MAX_SEQUENCE_LENGTH, EMBEDDING_DIM)\n",
    "print (x_train[:trial_samples].shape, output_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Adding Embeddings Layer to the model, which kind-of takes Input Layer as input\"\"\"\n",
    "embedded_sequences = embedding_layer(sequence_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Layers...\n",
    "\n",
    "Conv1D basically is a convolutional layer, applying 1D filters. For intuition, 2D filters are typically the ones applied for images. This is similar, but in 1D.\n",
    "\n",
    "The argument **filters** is basically how many filters would one like to use. So in image processing, if we use, say, 2 filters of (3, 3) *kernel_size* to check for certain edges / patterns in images, they could look like this (note that the numbers are for illustrative purpose only. In reality, the numbers are replaced by weights that need to be trained!)\n",
    "\n",
    "Filter 1 | Filter 2\n",
    "- | -\n",
    "![filter1](img/filter1.PNG) | ![filter2](img/filter2.PNG)\n",
    "\n",
    "In the case of 1D, they'd just be... 1D! Thus, in the layer below we are using 128 such filters of size 5 x 1 that we will train the weights of.\n",
    "\n",
    "**Important**:\n",
    "\n",
    "*Input shape* - 3D tensor with shape: (batch, steps, channels). In our case, (batch_size, MAX_SEQUENCE_LENGTH, EMBEDDING_DIM)\n",
    "\n",
    "*Output shape* - 3D tensor with shape: (batch, new_steps, filters). In our case, (batch_size, MAX_SEQUENCE_LENGTH - kernel_size + 1, 128), assuming stride = 1!\n",
    "\n",
    "To make the input / output shapes more clear, here's an example from Andrew Ng's course describing one part of the LeNet architecture:\n",
    "\n",
    "![LeNet](img/shape_clarity.PNG)\n",
    "\n",
    "You can see that the input image of 14x14 has 6 channels, to which 16 5x5 filters are applied with stride 1, leading to a shape of 10x10 with 16 channels. What is happening is that each filter is of a 5x5x6 dimension, and each filter outputs a 10x10 matrix, and all these matrices are stacked together to yield a 16-deep output tensor. Thus, for our 1D case, each of our input rows is of dimension MAX_SEQUENCE_LENGTH with EMBEDDING_DIM channels, which get changed to what was mentioned earlier, using the same logic as for the image example in LeNet.\n",
    "\n",
    "Also, for our case, due to above reasons, the number of parameters to train for this particular layer will be about 128 (# filters) * 5 (filter_size) * 100 (EMBEDDING_SIZE) = 64000. Additionally, we need to add 128 bias parameters too, bringing total parameters to be trained to 64,128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Convolutional Layer 1\"\"\"\n",
    "x = Conv1D(128, 5, activation='relu')(embedded_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max Pooling...\n",
    "\n",
    "Pretty straightforward - Chooses sub-chunks of 5 continuous data points in the 996-length sequence, and aggregates over them using a max function, yielding int(996 / 5) = 199 dimensions. **No difference in the channel_size**. Thus, output shape is (batch_size, 199, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = MaxPooling1D(5)(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv + MaxPool Layers, on repeat..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Conv1D(128, 5, activation='relu')(x)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(128, 5, activation='relu')(x)\n",
    "x = MaxPooling1D(35)(x)  # global max pooling, since input shape at this point is (batch_size, 35, 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flattening Layer...\n",
    "\n",
    "*One block of code is worth a thousand words!:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Tester Code from Docs\"\"\"\n",
    "_trial_model = Sequential()\n",
    "_trial_model.add(Conv2D(64, (3, 3), input_shape=(32, 32, 3), padding='same',))\n",
    "# now: model.output_shape == (None, 64, 32, 32)\n",
    "\n",
    "_trial_model.add(Flatten())\n",
    "# now: model.output_shape == (None, 65536)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Back to our model\"\"\"\n",
    "x = Flatten()(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense...\n",
    "\n",
    "Normal NN layer with 128 hidden units, and an input of (batch_size, 128) too. Seems like a bit of overkill! The second dense layer is outputting the predicted class, and has 20 hidden units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Dense(128, activation='relu')(x)\n",
    "preds = Dense(len(labels_index), activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model...\n",
    "\n",
    "Nothing new here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 1000, 100)         17407500  \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 996, 128)          64128     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 199, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 195, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 39, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 35, 128)           82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 1, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                2580      \n",
      "=================================================================\n",
      "Total params: 17,654,816\n",
      "Trainable params: 247,316\n",
      "Non-trainable params: 17,407,500\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs = sequence_input, outputs = preds)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning the parameters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15998 samples, validate on 3999 samples\n",
      "Epoch 1/2\n",
      "15998/15998 [==============================] - 1052s 66ms/step - loss: 2.2859 - acc: 0.2447 - val_loss: 1.7126 - val_acc: 0.4009\n",
      "Epoch 2/2\n",
      "15998/15998 [==============================] - 1014s 63ms/step - loss: 1.4550 - acc: 0.4899 - val_loss: 1.3690 - val_acc: 0.5289\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f596d0c76d8>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=2, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15998 samples, validate on 3999 samples\n",
      "Epoch 1/3\n",
      "15998/15998 [==============================] - 1012s 63ms/step - loss: 1.1133 - acc: 0.6120 - val_loss: 1.0767 - val_acc: 0.6294\n",
      "Epoch 2/3\n",
      "15998/15998 [==============================] - 1012s 63ms/step - loss: 0.9135 - acc: 0.6877 - val_loss: 1.0406 - val_acc: 0.6407\n",
      "Epoch 3/3\n",
      "15998/15998 [==============================] - 1038s 65ms/step - loss: 0.7590 - acc: 0.7415 - val_loss: 0.9803 - val_acc: 0.6657\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f596d0e2e80>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=3, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, after 5 epochs, we get about 66.5% accuracy on the validation test.\n",
    "\n",
    "Next, I'd have really liked to understand what is being outputted by the intermediate Conv1D layers, but I'm not sure how interpret this output. It doesn't seem exactly as straight-forward as CNN for images, which has packages at this point that allow one to easily \"peek into\" the network. Oh, well.!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:jupyter-apf]",
   "language": "python",
   "name": "conda-env-jupyter-apf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
